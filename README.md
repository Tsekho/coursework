# Курсовая работа

## Оглавление

- [Курсовая работа](#курсовая-работа)
  - [Оглавление](#оглавление)
  - [Параметры](#параметры)
  - [Суть](#суть)
  - [Использование скрипта](#использование-скрипта)
    - [Генерация ключей](#генерация-ключей)
    - [Обучение](#обучение)
      - [Аргументы](#аргументы)
  - [Опыты](#опыты)
    - [TODO](#todo)
  - [Репозитории](#репозитории)

## Параметры

- Набор данных [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)
  - 10 классов по 5000 тренировочных и 1000 валидационных изображений 32×32px
- 50 эпох
- 64 размер батча
- Сокращение веса 5e-4
- Момент 0.7
- Архитектуры:
  - [SimpleNetV1]("https://arxiv.org/abs/1608.06037")
  - [ResNet18, ResNet34, ResNet50](https://arxiv.org/abs/1512.03385v1)

## Суть

Клиент получает веса модели и полный набор данных.
После каждого батча обновляется внутренняя память (накопленный градиент, его моменты и разреженая часть градиента для отправки на сервер). Разреженый градиент отправляется на сервер и применяется локально, до следующего запроса актуальных параметров с сервера.

Сервер получает разреженые градиенты и обновляет параметры результирующей модели. В отличие от локального обновления клиента, обновление сервера также корректируется согласно устареванию.

Клиент может отключиться или подключиться в любой момент, задача равносильна у каждого из них.

Для конфигурации по умолчанию отправляемые градиенты весят 0.44Мб, принимаемые раз в 5 шагов веса модели 22Мб (компрессия градиентов ×0.01, разреженое представление ×2).

## Использование скрипта

### Генерация ключей

`python3 generate_keys.py`

- Клиент и сервер должны знать свой приватный ключ и публичный ключ другого, будут расположены по нужным папкам

### Обучение

`python3 train.py <args>`

#### Аргументы

- Общие:
  - `[-srv]` - сервер
  - Коммуникация:
    - `-ip localhost` - адрес сервера
    - `-p 51821` - порт
  - CUDA:
    - `[-cuda]` - использовать графический ускоритель, если возможно
  - Обучение:
    - `-e 50` - количество эпох
      - `-spe 1000` - шагов в каждой эпохе
    - `-net simplenetv1` - обучаемая архитектура
      - принимает `{resnet18, resnet34, resnet50}`
    - `-lr 0.05` - базовый шаг обучения
    - `-ms 30 40` - пороги для снижения шага
      - `=g 0.1` - коэффициент снижения
    - `-a 0.5` - коррекция устаревания
    - `-b 64` - размер батча
  - Вывод:
    - `[-s]` - не использовать стандартный вывод
- Сервер:
  - Вывод:
    - `[-tb]` - вести логи для TensorBoard
      - запуск сервиса `tensorboard --logdir="runs"`
      - будет доступен по `http://localhost:6006/`, если порт свободен и не указан другой
    - `[-csv]` - вести .csv логи
    - `-c -1` - промежуток для сохранения промежуточных и лучшего результатов
  - Обучение:
    - `-bnf 0.1` - доля обучающей выборки для обучения коэффициентов BN слоёв после каждой эпохи на сервере
    - не входят в градиент и слишком важны, нельзя разрежать
- Клиент
  - Обучение:
    - `-f 1.0` - доля обучающей выборки
    - `-wd 5e-4` - регуляризация весов модели (weight decay)
    - `-cn 1` - перенормировать градиент, если норма Фробениуса превысила порог
    - `-m 0.7` - коррекция моментом накапливаемого градиента
      - `[-n]` - момент Нестерова
    - `-cr 0.01` - коэффициент компрессии
  - Коммуникация
    - `-sppull 5` - промежуток обновления параметров модели
    - `-spr 50` - промежуток отправки накопленных логов

## Опыты

### TODO

- Зависимость скорости от количества
- Зависимость оптимального `-a` от количества
- Сравнение сходимости и качества против локального обучения одним устройством

## Репозитории

- [Deep Gradient Compression](https://github.com/synxlin/deep-gradient-compression) - распределённое обучение с Horovod и PyTorch, имплементация опорного метода [Y.Lin et al. [2017]](2)
  - [GRAdient ComprEssion for distributed deep learning](https://github.com/sands-lab/grace) - основа для имплементации выше
- [DGS PyTorch](https://github.com/yanring/DGS) - код работы [Z.Yan et al. [2019]](https://dl.acm.org/doi/10.1145/3404397.3404401), реализация других подходов, включая [A.Aji, K.Heafield [2017]](1)

[1]: https://arxiv.org/abs/1704.05021 "A.Aji, K.Heafield [2017]"
[2]: https://arxiv.org/abs/1712.01887 "Y.Lin et al. [2017]"
